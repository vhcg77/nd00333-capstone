{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import csv\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "import pkg_resources\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK version: 1.34.0\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1636310114488
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing.\n",
        "\n",
        "This dataset contains numerical input variables that come from and PCA algorithm. Due to confidential concerns, the original variables are not available. Features V1, V2, ..., V8 are the outputs of the principal components from the PCA algorithm. The time and amount are the variables that are not transformed by PCA. The target variable is the feature 'Class' and it takes values 1 in case of fraud and 0 otherwise.\n",
        "\n",
        "\n",
        "This dataset contains transations made by credit cards in September 2012 by European cardholders. This dataset contains 492 frauds out of 284807 transations, and it is highly unbalanced, the positive class (fraud) account for 0.172% of all the transations.\n",
        "\n",
        "\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "# choose a name for experiment\n",
        "experiment_name = 'telco-customer-churn'\n",
        "experiment=Experiment(ws, experiment_name)\n",
        "\n",
        "# Try to load the dataset from the Workspace. Otherwise, create it from the file\n",
        "# NOTE: update the key to match the dataset name\n",
        "found = False\n",
        "key = \"Customer Churn\"\n",
        "description_text = \"Customer Churn DataSet for Udacity Capstone Project\"\n",
        "\n",
        "if key in ws.datasets.keys(): \n",
        "        found = True\n",
        "        dataset = ws.datasets[key] \n",
        "\n",
        "if not found:\n",
        "        # Create AML Dataset and register it into Workspace\n",
        "        example_data = 'https://raw.githubusercontent.com/srees1988/predict-churn-py/main/customer_churn_data.csv'\n",
        "        dataset = Dataset.Tabular.from_delimited_files(example_data)        \n",
        "        #Register Dataset in Workspace\n",
        "        dataset = dataset.register(workspace=ws,\n",
        "                                   name=key,\n",
        "                                   description=description_text)\n",
        "\n",
        "\n",
        "df = dataset.to_pandas_dataframe()\n",
        "df.describe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "       SeniorCitizen       tenure  MonthlyCharges  TotalCharges\ncount    7043.000000  7043.000000     7043.000000   7032.000000\nmean        0.162147    32.371149       64.761692   2283.300441\nstd         0.368612    24.559481       30.090047   2266.771362\nmin         0.000000     0.000000       18.250000     18.800000\n25%         0.000000     9.000000       35.500000    401.450000\n50%         0.000000    29.000000       70.350000   1397.475000\n75%         0.000000    55.000000       89.850000   3794.737500\nmax         1.000000    72.000000      118.750000   8684.800000",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SeniorCitizen</th>\n      <th>tenure</th>\n      <th>MonthlyCharges</th>\n      <th>TotalCharges</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>7043.000000</td>\n      <td>7043.000000</td>\n      <td>7043.000000</td>\n      <td>7032.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.162147</td>\n      <td>32.371149</td>\n      <td>64.761692</td>\n      <td>2283.300441</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.368612</td>\n      <td>24.559481</td>\n      <td>30.090047</td>\n      <td>2266.771362</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>18.250000</td>\n      <td>18.800000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>9.000000</td>\n      <td>35.500000</td>\n      <td>401.450000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>29.000000</td>\n      <td>70.350000</td>\n      <td>1397.475000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>55.000000</td>\n      <td>89.850000</td>\n      <td>3794.737500</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>72.000000</td>\n      <td>118.750000</td>\n      <td>8684.800000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1636310125095
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the first five rows:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "   customerID  gender  SeniorCitizen  Partner  Dependents  tenure  \\\n0  7590-VHVEG  Female              0     True       False       1   \n1  5575-GNVDE    Male              0    False       False      34   \n2  3668-QPYBK    Male              0    False       False       2   \n3  7795-CFOCW    Male              0    False       False      45   \n4  9237-HQITU  Female              0    False       False       2   \n\n   PhoneService     MultipleLines InternetService OnlineSecurity  ...  \\\n0         False  No phone service             DSL             No  ...   \n1          True                No             DSL            Yes  ...   \n2          True                No             DSL            Yes  ...   \n3         False  No phone service             DSL            Yes  ...   \n4          True                No     Fiber optic             No  ...   \n\n  DeviceProtection TechSupport StreamingTV StreamingMovies        Contract  \\\n0               No          No          No              No  Month-to-month   \n1              Yes          No          No              No        One year   \n2               No          No          No              No  Month-to-month   \n3              Yes         Yes          No              No        One year   \n4               No          No          No              No  Month-to-month   \n\n  PaperlessBilling              PaymentMethod MonthlyCharges  TotalCharges  \\\n0             True           Electronic check          29.85         29.85   \n1            False               Mailed check          56.95       1889.50   \n2             True               Mailed check          53.85        108.15   \n3            False  Bank transfer (automatic)          42.30       1840.75   \n4             True           Electronic check          70.70        151.65   \n\n   Churn  \n0  False  \n1  False  \n2   True  \n3  False  \n4   True  \n\n[5 rows x 21 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customerID</th>\n      <th>gender</th>\n      <th>SeniorCitizen</th>\n      <th>Partner</th>\n      <th>Dependents</th>\n      <th>tenure</th>\n      <th>PhoneService</th>\n      <th>MultipleLines</th>\n      <th>InternetService</th>\n      <th>OnlineSecurity</th>\n      <th>...</th>\n      <th>DeviceProtection</th>\n      <th>TechSupport</th>\n      <th>StreamingTV</th>\n      <th>StreamingMovies</th>\n      <th>Contract</th>\n      <th>PaperlessBilling</th>\n      <th>PaymentMethod</th>\n      <th>MonthlyCharges</th>\n      <th>TotalCharges</th>\n      <th>Churn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7590-VHVEG</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>1</td>\n      <td>False</td>\n      <td>No phone service</td>\n      <td>DSL</td>\n      <td>No</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>True</td>\n      <td>Electronic check</td>\n      <td>29.85</td>\n      <td>29.85</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5575-GNVDE</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>34</td>\n      <td>True</td>\n      <td>No</td>\n      <td>DSL</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>One year</td>\n      <td>False</td>\n      <td>Mailed check</td>\n      <td>56.95</td>\n      <td>1889.50</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3668-QPYBK</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2</td>\n      <td>True</td>\n      <td>No</td>\n      <td>DSL</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>True</td>\n      <td>Mailed check</td>\n      <td>53.85</td>\n      <td>108.15</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7795-CFOCW</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>45</td>\n      <td>False</td>\n      <td>No phone service</td>\n      <td>DSL</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>One year</td>\n      <td>False</td>\n      <td>Bank transfer (automatic)</td>\n      <td>42.30</td>\n      <td>1840.75</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9237-HQITU</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2</td>\n      <td>True</td>\n      <td>No</td>\n      <td>Fiber optic</td>\n      <td>No</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>True</td>\n      <td>Electronic check</td>\n      <td>70.70</td>\n      <td>151.65</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 21 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1636310146445
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The column customerID should be removed because they have unique values in the whole column:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['customerID'].nunique() == df.shape[0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1636310148955
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('customerID', axis=1, inplace=True)\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "   gender  SeniorCitizen  Partner  Dependents  tenure  PhoneService  \\\n0  Female              0     True       False       1         False   \n1    Male              0    False       False      34          True   \n2    Male              0    False       False       2          True   \n3    Male              0    False       False      45         False   \n4  Female              0    False       False       2          True   \n\n      MultipleLines InternetService OnlineSecurity OnlineBackup  \\\n0  No phone service             DSL             No          Yes   \n1                No             DSL            Yes           No   \n2                No             DSL            Yes          Yes   \n3  No phone service             DSL            Yes           No   \n4                No     Fiber optic             No           No   \n\n  DeviceProtection TechSupport StreamingTV StreamingMovies        Contract  \\\n0               No          No          No              No  Month-to-month   \n1              Yes          No          No              No        One year   \n2               No          No          No              No  Month-to-month   \n3              Yes         Yes          No              No        One year   \n4               No          No          No              No  Month-to-month   \n\n   PaperlessBilling              PaymentMethod  MonthlyCharges  TotalCharges  \\\n0              True           Electronic check           29.85         29.85   \n1             False               Mailed check           56.95       1889.50   \n2              True               Mailed check           53.85        108.15   \n3             False  Bank transfer (automatic)           42.30       1840.75   \n4              True           Electronic check           70.70        151.65   \n\n   Churn  \n0  False  \n1  False  \n2   True  \n3  False  \n4   True  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>SeniorCitizen</th>\n      <th>Partner</th>\n      <th>Dependents</th>\n      <th>tenure</th>\n      <th>PhoneService</th>\n      <th>MultipleLines</th>\n      <th>InternetService</th>\n      <th>OnlineSecurity</th>\n      <th>OnlineBackup</th>\n      <th>DeviceProtection</th>\n      <th>TechSupport</th>\n      <th>StreamingTV</th>\n      <th>StreamingMovies</th>\n      <th>Contract</th>\n      <th>PaperlessBilling</th>\n      <th>PaymentMethod</th>\n      <th>MonthlyCharges</th>\n      <th>TotalCharges</th>\n      <th>Churn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Female</td>\n      <td>0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>1</td>\n      <td>False</td>\n      <td>No phone service</td>\n      <td>DSL</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>True</td>\n      <td>Electronic check</td>\n      <td>29.85</td>\n      <td>29.85</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Male</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>34</td>\n      <td>True</td>\n      <td>No</td>\n      <td>DSL</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>One year</td>\n      <td>False</td>\n      <td>Mailed check</td>\n      <td>56.95</td>\n      <td>1889.50</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Male</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2</td>\n      <td>True</td>\n      <td>No</td>\n      <td>DSL</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>True</td>\n      <td>Mailed check</td>\n      <td>53.85</td>\n      <td>108.15</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Male</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>45</td>\n      <td>False</td>\n      <td>No phone service</td>\n      <td>DSL</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>One year</td>\n      <td>False</td>\n      <td>Bank transfer (automatic)</td>\n      <td>42.30</td>\n      <td>1840.75</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Female</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2</td>\n      <td>True</td>\n      <td>No</td>\n      <td>Fiber optic</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>True</td>\n      <td>Electronic check</td>\n      <td>70.70</td>\n      <td>151.65</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1636310149740
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the data types present along the columns:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "gender               object\nSeniorCitizen         int64\nPartner                bool\nDependents             bool\ntenure                int64\nPhoneService           bool\nMultipleLines        object\nInternetService      object\nOnlineSecurity       object\nOnlineBackup         object\nDeviceProtection     object\nTechSupport          object\nStreamingTV          object\nStreamingMovies      object\nContract             object\nPaperlessBilling       bool\nPaymentMethod        object\nMonthlyCharges      float64\nTotalCharges        float64\nChurn                  bool\ndtype: object"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1636310152087
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the missing values:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check missing values\n",
        "df.isnull().sum()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "gender               0\nSeniorCitizen        0\nPartner              0\nDependents           0\ntenure               0\nPhoneService         0\nMultipleLines        0\nInternetService      0\nOnlineSecurity       0\nOnlineBackup         0\nDeviceProtection     0\nTechSupport          0\nStreamingTV          0\nStreamingMovies      0\nContract             0\nPaperlessBilling     0\nPaymentMethod        0\nMonthlyCharges       0\nTotalCharges        11\nChurn                0\ndtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1636310158466
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the unique values of the float columns:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "float_columns = df.select_dtypes(include=['float64']).columns\n",
        "print(float_columns)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Index(['MonthlyCharges', 'TotalCharges'], dtype='object')\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1636310167282
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in float_columns:\n",
        "    print(df[column].value_counts())\n",
        "    print('\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "20.05     61\n19.85     45\n19.95     44\n19.90     44\n20.00     43\n          ..\n114.75     1\n103.60     1\n113.40     1\n57.65      1\n113.30     1\nName: MonthlyCharges, Length: 1585, dtype: int64\n\n\n20.20      11\n19.75       9\n19.65       8\n20.05       8\n19.90       8\n           ..\n1066.15     1\n249.95      1\n8333.95     1\n7171.70     1\n1024.00     1\nName: TotalCharges, Length: 6530, dtype: int64\n\n\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1636310167921
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the unique values of the float columns:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bool_columns = df.select_dtypes(include=['bool']).columns\n",
        "print(bool_columns)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Index(['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Churn'], dtype='object')\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1636310174187
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in bool_columns:\n",
        "    print(df[column].value_counts())\n",
        "    print('\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "False    3641\nTrue     3402\nName: Partner, dtype: int64\n\n\nFalse    4933\nTrue     2110\nName: Dependents, dtype: int64\n\n\nTrue     6361\nFalse     682\nName: PhoneService, dtype: int64\n\n\nTrue     4171\nFalse    2872\nName: PaperlessBilling, dtype: int64\n\n\nFalse    5174\nTrue     1869\nName: Churn, dtype: int64\n\n\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1636310175133
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "5174/1864"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "2.7757510729613735"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1636310180820
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The variable Churn is highly skewed toward False by a factor of 2.77"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the unique values of the object columns:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "object_columns = df.select_dtypes(include=['object']).columns\n",
        "print(object_columns)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Index(['gender', 'MultipleLines', 'InternetService', 'OnlineSecurity',\n       'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n       'StreamingMovies', 'Contract', 'PaymentMethod'],\n      dtype='object')\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1636310184618
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in object_columns:\n",
        "    print(df[column].value_counts())\n",
        "    print('\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Male      3555\nFemale    3488\nName: gender, dtype: int64\n\n\nNo                  3390\nYes                 2971\nNo phone service     682\nName: MultipleLines, dtype: int64\n\n\nFiber optic    3096\nDSL            2421\nNo             1526\nName: InternetService, dtype: int64\n\n\nNo                     3498\nYes                    2019\nNo internet service    1526\nName: OnlineSecurity, dtype: int64\n\n\nNo                     3088\nYes                    2429\nNo internet service    1526\nName: OnlineBackup, dtype: int64\n\n\nNo                     3095\nYes                    2422\nNo internet service    1526\nName: DeviceProtection, dtype: int64\n\n\nNo                     3473\nYes                    2044\nNo internet service    1526\nName: TechSupport, dtype: int64\n\n\nNo                     2810\nYes                    2707\nNo internet service    1526\nName: StreamingTV, dtype: int64\n\n\nNo                     2785\nYes                    2732\nNo internet service    1526\nName: StreamingMovies, dtype: int64\n\n\nMonth-to-month    3875\nTwo year          1695\nOne year          1473\nName: Contract, dtype: int64\n\n\nElectronic check             2365\nMailed check                 1612\nBank transfer (automatic)    1544\nCredit card (automatic)      1522\nName: PaymentMethod, dtype: int64\n\n\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1636310186764
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test Splitting"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.exceptions import UserErrorException\r\n",
        "\r\n",
        "blob_datastore_name='data_storage'\r\n",
        "account_name=os.getenv(\"BLOB_ACCOUNTNAME_62\", \"mlstrg162961\") # Storage account name\r\n",
        "container_name=os.getenv(\"BLOB_CONTAINER_62\", \"azureml\") # Name of Azure blob container\r\n",
        "account_key=os.getenv(\"BLOB_ACCOUNT_KEY_62\", \"yzqg7jQBdfeTMfw2yrQFyDQjWxeSlYjxoqsy4p/TApRjFIic4wNVL8niR9r6mIa+heYVeJNdzWrEaW5SxLIxfA==\") # Storage account key\r\n",
        "\r\n",
        "try:\r\n",
        "    blob_datastore = Datastore.get(ws, blob_datastore_name)\r\n",
        "    print(\"Found Blob Datastore with name: %s\" % blob_datastore_name)\r\n",
        "except UserErrorException:\r\n",
        "    blob_datastore = Datastore.register_azure_blob_container(\r\n",
        "                        workspace=ws,\r\n",
        "                        datastore_name=blob_datastore_name,\r\n",
        "                        account_name=account_name, # Storage account name\r\n",
        "                        container_name=container_name, # Name of Azure blob container\r\n",
        "                        account_key=account_key) # Storage account key\r\n",
        "\r\n",
        "    print(\"Registered blob datastore with name: %s\" % blob_datastore_name)\r\n",
        "\r\n",
        "blob_data_ref = DataReference(\r\n",
        "    datastore=blob_datastore,\r\n",
        "    data_reference_name=\"blob_test_data\",\r\n",
        "    path_on_datastore=\"testdata\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "description_text = \"Train and Test splitting from Customer Churn DataSet for Udacity Capstone Project\"\n",
        "datastore_split_name = 'data_splitted'\n",
        "\n",
        "churn = df['Churn']\n",
        "\n",
        "# Split data into train and test data taking into account the variable Churn is highly skewed:\n",
        "train_dataset, test_dataset = train_test_split(df, test_size=0.2, stratify=churn, random_state=42)\n",
        "\n",
        "directory = 'train'\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n",
        "    \n",
        "directory = 'test'\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n",
        "\n",
        "# Export data as csv\n",
        "train_dataset.to_csv(\"train_data.csv\", index=False)\n",
        "test_dataset.to_csv(\"test_data.csv\", index=False)\n",
        "\n",
        "# # Upload data to the datastore\n",
        "# datastore = ws.get_default_datastore()\n",
        "datastore = ws.get(ws, datastore_split_name)\n",
        "datastore.upload(src_dir='./train', target_path = experiment_name)\n",
        "datastore.upload(src_dir='./test', target_path = experiment_name)\n",
        "\n",
        "# train_dataset_azure = TabularDatasetFactory.from_delimited_files(path=datastore.path(\"capstone/train_data.csv\"))\n",
        "# test_dataset_azure = TabularDatasetFactory.from_delimited_files(path=datastore.path(\"capstone/test_data.csv\"))"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute '_get_service_client'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-14c0097e12c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# # Upload data to the datastore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# datastore = ws.get_default_datastore()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mdatastore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatastore_split_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mdatastore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mdatastore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/workspace.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(name, auth, subscription_id, resource_group, location, cloud, id)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0m_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0m_cloud\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             _workspace_id=id)\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/workspace.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, subscription_id, resource_group, workspace_name, auth, _location, _disable_service_check, _workspace_id, sku, tags, _cloud)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_disable_service_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             auto_rest_workspace = _commands.get_workspace(\n\u001b[0;32m--> 210\u001b[0;31m                 auth, subscription_id, resource_group, workspace_name, _location, _cloud, _workspace_id)\n\u001b[0m\u001b[1;32m    211\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workspace_autorest_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauto_rest_workspace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_project/_commands.py\u001b[0m in \u001b[0;36mget_workspace\u001b[0;34m(auth, subscription_id, resource_group_name, workspace_name, location, cloud, workspace_id)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \"\"\"\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         workspaces = auth._get_service_client(\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0mAzureMachineLearningWorkspaces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m      subscription_id).workspaces\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute '_get_service_client'"
          ]
        }
      ],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1636315484649
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = Dataset.Tabular.from_delimited_files(path = [(datastore, (\"train_data.csv\"))])\n",
        "dataset_test = Dataset.Tabular.from_delimited_files(path = [(datastore, (\"test_data.csv\"))])\n",
        "\n",
        "# dataset_train"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "DatasetValidationError",
          "evalue": "DatasetValidationError:\n\tMessage: Cannot load any data from the specified path. Make sure the path is accessible and contains data.\nScriptExecutionException was caused by StreamAccessException.\n  StreamAccessException was caused by NotFoundException.\n    Found no resources for the input provided: '[REDACTED]'\n| session_id=fa7f0689-4c35-49da-b894-142a8354f102\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Cannot load any data from the specified path. Make sure the path is accessible and contains data.\\nScriptExecutionException was caused by StreamAccessException.\\n  StreamAccessException was caused by NotFoundException.\\n    Found no resources for the input provided: '[REDACTED]'\\n| session_id=fa7f0689-4c35-49da-b894-142a8354f102\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mExecutionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/data/dataset_error_handling.py\u001b[0m in \u001b[0;36m_validate_has_data\u001b[0;34m(dataflow, error_message)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mdataflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverify_has_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     except (dataprep().api.dataflow.DataflowValidationError,\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/dataprep/api/_loggerfactory.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/dataprep/api/dataflow.py\u001b[0m in \u001b[0;36mverify_has_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_pyrecords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mDataflowValidationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The Dataflow produced no records.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/dataprep/api/dataflow.py\u001b[0m in \u001b[0;36m_to_pyrecords\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    792\u001b[0m                         \u001b[0manonymous_activity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDataflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataflow_to_anonymous_activity_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataflow_to_execute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m                         \u001b[0mspan_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_dprep_span_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mspan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m                     ))\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/dataprep/api/_aml_helper.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(op_code, message, cancellation_token)\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mengine_api_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_environment_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchanged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msend_message_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/dataprep/api/engineapi/api.py\u001b[0m in \u001b[0;36mexecute_anonymous_activity\u001b[0;34m(self, message_args, cancellation_token)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute_anonymous_activity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtypedefinitions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecuteAnonymousActivityMessageArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_token\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCancellationToken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_channel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Engine.ExecuteActivity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/dataprep/api/engineapi/engine.py\u001b[0m in \u001b[0;36msend_message\u001b[0;34m(self, op_code, message, cancellation_token)\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mcancel_on_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0mraise_engine_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/dataprep/api/errorhandlers.py\u001b[0m in \u001b[0;36mraise_engine_error\u001b[0;34m(error_response)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'ScriptExecution'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0merror_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mExecutionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'Validation'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0merror_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mExecutionError\u001b[0m: \nError Code: ScriptExecution.StreamAccess.NotFound\nFailed Step: dfa984d3-6a1b-4929-8fbd-e92c1c5b1393\nError Message: ScriptExecutionException was caused by StreamAccessException.\n  StreamAccessException was caused by NotFoundException.\n    Found no resources for the input provided: 'https://mlstrg162961.blob.core.windows.net/azureml-blobstore-e90aecb4-6e4f-493d-a9fe-780ed457006a/train_data.csv'\n| session_id=fa7f0689-4c35-49da-b894-142a8354f102",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mDatasetValidationError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-04e242a12c19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTabular\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_delimited_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatastore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"train_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataset_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTabular\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_delimited_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatastore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"test_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# dataset_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/data/_loggerfactory.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_LoggerFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_activity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivity_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_dimensions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'activity_info'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'error_code'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/data/dataset_factory.py\u001b[0m in \u001b[0;36mfrom_delimited_files\u001b[0;34m(path, validate, include_path, infer_column_types, set_column_types, separator, header, partition_format, support_multi_line, empty_as_string, encoding)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0mdataflow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m             infer_column_types or _is_inference_required(set_column_types))\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minfer_column_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0mcolumn_types_builder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_column_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/data/dataset_factory.py\u001b[0m in \u001b[0;36m_transform_and_validate\u001b[0;34m(dataflow, partition_format, include_path, validate, infer_column_types)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0mdataflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Path'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m         _validate_has_data(dataflow, 'Cannot load any data from the specified path. '\n\u001b[0m\u001b[1;32m   1170\u001b[0m                                      'Make sure the path is accessible and contains data.')\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minfer_column_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/data/dataset_error_handling.py\u001b[0m in \u001b[0;36m_validate_has_data\u001b[0;34m(dataflow, error_message)\u001b[0m\n\u001b[1;32m     66\u001b[0m     except (dataprep().api.dataflow.DataflowValidationError,\n\u001b[1;32m     67\u001b[0m             dataprep().api.errorhandlers.ExecutionError) as e:\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mDatasetValidationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompliant_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDatasetValidationError\u001b[0m: DatasetValidationError:\n\tMessage: Cannot load any data from the specified path. Make sure the path is accessible and contains data.\nScriptExecutionException was caused by StreamAccessException.\n  StreamAccessException was caused by NotFoundException.\n    Found no resources for the input provided: '[REDACTED]'\n| session_id=fa7f0689-4c35-49da-b894-142a8354f102\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Cannot load any data from the specified path. Make sure the path is accessible and contains data.\\nScriptExecutionException was caused by StreamAccessException.\\n  StreamAccessException was caused by NotFoundException.\\n    Found no resources for the input provided: '[REDACTED]'\\n| session_id=fa7f0689-4c35-49da-b894-142a8354f102\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1636312243651
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cluster Provisioning\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# TODO: Create compute cluster\n",
        "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
        "# max_nodes should be no greater than 4.\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "cluster_name = \"cluster-vhcg\"\n",
        "# verify that the cluster does not exist already\n",
        "try:\n",
        "    cpu_cluster = ComputeTarget(workspace=ws, name = cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_D2_V2', max_nodes = 4, idle_seconds_before_scaledown=120)\n",
        "    cpu_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "\n",
        "cpu_cluster.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "InProgress....\nSucceededProvisioning operation finished, operation \"Succeeded\"\nSucceeded\nAmlCompute wait for completion finished\n\nMinimum number of nodes requested have been provisioned\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1636312274986
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "TODO: Explain why you chose the automl settings and cofiguration you used below."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Put your automl config here\n",
        "automl_config = AutoMLConfig(\n",
        "                                compute_target=cluster_name,\n",
        "                                task='classification',\n",
        "                                training_data=train_dataset,\n",
        "                                test_data = test_dataset,\n",
        "                                label_column_name='Churn',\n",
        "                                # n_cross_validations=10,\n",
        "                                # validation_size=0.2,\n",
        "                                primary_metric='AUC_weighted',\n",
        "                                experiment_timeout_minutes=30,\n",
        "                                max_concurrent_iterations=5,\n",
        "                                max_cores_per_iteration=-1, \n",
        "\n",
        "                                )"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1636312399354
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Submit your experiment\n",
        "from azureml.widgets import RunDetails\n",
        "run = experiment.submit(config=automl_config, show_output=True)\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConfigException",
          "evalue": "ConfigException:\n\tMessage: Input of type '<class 'pandas.core.frame.DataFrame'>' is not supported. Supported types: [azureml.data.tabular_dataset.TabularDataset]Please refer to documentation for converting to Supported types: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.dataset.dataset?view=azure-ml-py\n\tInnerException: None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Input of type '<class 'pandas.core.frame.DataFrame'>' is not supported. Supported types: [azureml.data.tabular_dataset.TabularDataset]Please refer to documentation for converting to Supported types: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.dataset.dataset?view=azure-ml-py\",\n        \"details_uri\": \"https://aka.ms/AutoMLConfig\",\n        \"target\": \"training_data\",\n        \"inner_error\": {\n            \"code\": \"BadArgument\",\n            \"inner_error\": {\n                \"code\": \"ArgumentInvalid\",\n                \"inner_error\": {\n                    \"code\": \"InvalidInputDatatype\"\n                }\n            }\n        }\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConfigException\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-eb67aa7b5177>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO: Submit your experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidgets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRunDetails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautoml_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mRunDetails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/experiment.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, config, tags, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0msubmit_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_experiment_submit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"submit config {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/train/automl/automlconfig.py\u001b[0m in \u001b[0;36m_automl_static_submit\u001b[0;34m(automl_config_object, workspace, experiment_name, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mcompute_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoml_config_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'compute_target'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mautoml_config_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_config_settings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoml_config_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/train/automl/automlconfig.py\u001b[0m in \u001b[0;36m_validate_config_settings\u001b[0;34m(self, workspace)\u001b[0m\n\u001b[1;32m   2054\u001b[0m                     AzureMLError.create(\n\u001b[1;32m   2055\u001b[0m                         \u001b[0mInvalidInputDatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m                         \u001b[0msupported_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSupportedInputDatatypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTABULAR_DATASET\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2057\u001b[0m                     )\n\u001b[1;32m   2058\u001b[0m                 )\n",
            "\u001b[0;31mConfigException\u001b[0m: ConfigException:\n\tMessage: Input of type '<class 'pandas.core.frame.DataFrame'>' is not supported. Supported types: [azureml.data.tabular_dataset.TabularDataset]Please refer to documentation for converting to Supported types: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.dataset.dataset?view=azure-ml-py\n\tInnerException: None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Input of type '<class 'pandas.core.frame.DataFrame'>' is not supported. Supported types: [azureml.data.tabular_dataset.TabularDataset]Please refer to documentation for converting to Supported types: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.dataset.dataset?view=azure-ml-py\",\n        \"details_uri\": \"https://aka.ms/AutoMLConfig\",\n        \"target\": \"training_data\",\n        \"inner_error\": {\n            \"code\": \"BadArgument\",\n            \"inner_error\": {\n                \"code\": \"ArgumentInvalid\",\n                \"inner_error\": {\n                    \"code\": \"InvalidInputDatatype\"\n                }\n            }\n        }\n    }\n}"
          ]
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1633974659605
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve and save your best automl model.\n",
        "\n",
        "best_automl_run, fitted_automl_model = run.get_output()\n",
        "print(best_automl_run)\n",
        "\n",
        "print(\"Best run metrics: \")\n",
        "best_automl_run.get_metrics()\n",
        "fitted_automl_model"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Run(Experiment: telco-customer-churn,\nId: AutoML_14e70e02-a31c-4dc2-88df-f660af838a84_34,\nType: azureml.scriptrun,\nStatus: Completed)\nBest run metrics: \n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "PipelineWithYTransformations(Pipeline={'memory': None,\n                                       'steps': [('datatransformer',\n                                                  DataTransformer(enable_dnn=False, enable_feature_sweeping=True, feature_sweeping_config={}, feature_sweeping_timeout=86400, featurization_config=None, force_text_dnn=False, is_cross_validation=True, is_onnx_compatible=False, observer=None, task='classification', working_dir='/mn...\n), random_state=0, reg_alpha=0, reg_lambda=0.625, subsample=0.8, tree_method='auto'))], verbose=False)), ('25', Pipeline(memory=None, steps=[('truncatedsvdwrapper', TruncatedSVDWrapper(n_components=0.3068421052631579, random_state=None)), ('randomforestclassifier', RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None, criterion='entropy', max_depth=None, max_features=0.1, max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=0.3194736842105263, min_samples_split=0.6189473684210526, min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1, oob_score=True, random_state=None, verbose=0, warm_start=False))], verbose=False))], flatten_transform=None, weights=[0.2, 0.13333333333333333, 0.13333333333333333, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.13333333333333333, 0.06666666666666667, 0.13333333333333333]))],\n                                       'verbose': False},\n                             y_transformer={},\n                             y_transformer_name='LabelEncoder')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1633974931761
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Save the best model\n",
        "\n",
        "\n",
        "#print(best_automl_run.get_file_names())\n",
        "\n",
        "models = [element for element in best_automl_run.get_file_names() if 'pkl' in element]\n",
        "models\n",
        "for model in models:\n",
        "    best_automl_run.download_file(name=model)"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1633974936900
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline = pipeline_run.publish_pipeline(\n",
        "    name=\"Bankmarketing Train\", description=\"Training bankmarketing pipeline\", version=\"1.0\")\n",
        "\n",
        "published_pipeline"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431435189
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "rest_endpoint = published_pipeline.endpoint\n",
        "response = requests.post(rest_endpoint, \n",
        "                         headers=auth_header, \n",
        "                         json={\"ExperimentName\": \"pipeline-rest-endpoint\"}\n",
        "                        )\n",
        "\n",
        "\n",
        "try:\n",
        "    response.raise_for_status()\n",
        "except Exception:    \n",
        "    raise Exception(\"Received bad response from the endpoint: {}\\n\"\n",
        "                    \"Response Code: {}\\n\"\n",
        "                    \"Headers: {}\\n\"\n",
        "                    \"Content: {}\".format(rest_endpoint, response.status_code, response.headers, response.content))\n",
        "\n",
        "run_id = response.json().get('Id')\n",
        "print('Submitted pipeline run: ', run_id)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598432707604
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core.run import PipelineRun\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "published_pipeline_run = PipelineRun(ws.experiments[\"pipeline-rest-endpoint\"], run_id)\n",
        "RunDetails(published_pipeline_run).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}